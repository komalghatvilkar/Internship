{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3505bec3",
   "metadata": {},
   "source": [
    "# Web Scraping - Selenium Assignment 2\n",
    "\n",
    "Before Starting With The Assignment We Need To Do Or Check With Following Things :\n",
    "\n",
    "- We Need To Install Selenium If Not Installed For Scrape The Required Data,\n",
    "\n",
    "- Need To Import Some Necessary Libraries For The Tasks To Perform,\n",
    "\n",
    "- Need To Connect To Web Driver By Installing the Suitable Web Driver For Your System & Browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c38bf5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d357d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba305426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect To Web Driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3754942b",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "\n",
    "Answer :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0c6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57c5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Web Element For Search Job Bar -\n",
    "search_job = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "# Write on search bar\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b206c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Web Element For search Location Bar Using Absolute Xpath -\n",
    "search_locn = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "# Write on search bar\n",
    "search_locn.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf09d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Search Using Absolute Xpath Function -\n",
    "search_btn = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "# Search Button Will Get Clicked\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab37cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract All The Data Needed From The Site - Scrape The Job-Title, Job-Location, Company_Name, Experience_Required -\n",
    "\n",
    "# Job Titles -\n",
    "title_tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "# Job Location -\n",
    "locn_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "# Company -\n",
    "company_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "# Experience - \n",
    "exp_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcec707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Clinical Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Labcorp Drug Development India Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consultant - Data Analyst</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Analyst/ Scientist- Fresher Position</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Sejal Consulting Hub</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring Data Analyst For Global Logic-Immediate...</td>\n",
       "      <td>Noida, Nagpur, Pune, Gurgaon/Gurugram, Bangalo...</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead - Data Analyst / Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Axim Technologies</td>\n",
       "      <td>12-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst / Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst - CRM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek Tech</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                    Assistant Clinical Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                          Consultant - Data Analyst   \n",
       "4   Junior Data Analyst/ Scientist- Fresher Position   \n",
       "5  Hiring Data Analyst For Global Logic-Immediate...   \n",
       "6                    Lead - Data Analyst / Scientist   \n",
       "7                    Data Analyst / Sr. Data Analyst   \n",
       "8                          Senior Data Analyst - CRM   \n",
       "9     Business Data Analyst - Database Design/Mining   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bengaluru/Bangalore   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bengaluru/Bangalore   \n",
       "3                                Bengaluru/Bangalore   \n",
       "4  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "5  Noida, Nagpur, Pune, Gurgaon/Gurugram, Bangalo...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                     Company Name Job Experience  \n",
       "0                                        Flipkart        4-6 Yrs  \n",
       "1  Labcorp Drug Development India Private Limited        0-2 Yrs  \n",
       "2                                        Flipkart        1-2 Yrs  \n",
       "3                                        Flipkart        1-3 Yrs  \n",
       "4                            Sejal Consulting Hub        0-3 Yrs  \n",
       "5                                     GlobalLogic        4-8 Yrs  \n",
       "6                               Axim Technologies      12-14 Yrs  \n",
       "7                                          Vmware        3-6 Yrs  \n",
       "8                                      Gojek Tech        2-5 Yrs  \n",
       "9                                     AugmatrixGo        2-5 Yrs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Text From Elements -\n",
    "job_title = []\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "location = []\n",
    "for i in locn_tags:\n",
    "    location.append(i.text)\n",
    "\n",
    "Company_name = []\n",
    "for i in company_tags:\n",
    "    Company_name.append(i.text)\n",
    "\n",
    "Experience = []\n",
    "for i in exp_tags:\n",
    "    Experience.append(i.text)\n",
    "    \n",
    "# Dataframe of all the tabs\n",
    "jobs=pd.DataFrame()\n",
    "jobs['Job Title']=job_title[:10]\n",
    "jobs['Job Location']=location[:10]\n",
    "jobs['Company Name']=Company_name[:10]\n",
    "jobs['Job Experience']=Experience[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9279dc",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "\n",
    "Answer :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1d21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f845422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Web Element For Search Job Bar -\n",
    "job = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "# Write on search bar\n",
    "job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d32f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Web Element For search Location Bar Using Absolute Xpath -\n",
    "locn = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "# Write on search bar\n",
    "locn.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19bcfe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Search Using Absolute Xpath Function -\n",
    "search = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "# Search Button Will Get Clicked\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16671581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract All The Data Needed From The Site - Scrape The Job-Title, Job-Location, Company_Name -\n",
    "\n",
    "# Job Titles -\n",
    "title = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "# Job Location -\n",
    "locn_ = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "# Company -\n",
    "company = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddae807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior/Lead Data Scientist - (Revenue Management)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>o9 Solutions Management India Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior/Lead - Data Scientist (Supply Chain)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>o9 Solutions Management India Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr . Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Harman Connected Services Corporation India Pvt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Slice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Gadgeon Smart Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Senior/Lead Data Scientist - (Revenue Management)   \n",
       "1        Senior/Lead - Data Scientist (Supply Chain)   \n",
       "2                 Data Scientist: Advanced Analytics   \n",
       "3                 Data Scientist: Advanced Analytics   \n",
       "4                                 Sr. Data Scientist   \n",
       "5                                Sr . Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7                                  Sr Data Scientist   \n",
       "8                                Lead Data Scientist   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                              Job Location  \\\n",
       "0                      Bangalore/Bengaluru   \n",
       "1                      Bangalore/Bengaluru   \n",
       "2                      Bangalore/Bengaluru   \n",
       "3                      Bengaluru/Bangalore   \n",
       "4                      Bangalore/Bengaluru   \n",
       "5                      Bangalore/Bengaluru   \n",
       "6                      Bangalore/Bengaluru   \n",
       "7                      Bangalore/Bengaluru   \n",
       "8  Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "9                      Bangalore/Bengaluru   \n",
       "\n",
       "                                       Company Name  \n",
       "0     o9 Solutions Management India Private Limited  \n",
       "1     o9 Solutions Management India Private Limited  \n",
       "2                                               IBM  \n",
       "3                                               IBM  \n",
       "4                                           Siemens  \n",
       "5  Harman Connected Services Corporation India Pvt.  \n",
       "6                                             Slice  \n",
       "7                                           Siemens  \n",
       "8                             Gadgeon Smart Systems  \n",
       "9                                              Dell  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Text From Elements -\n",
    "job_ = []\n",
    "for i in title:\n",
    "    job_.append(i.text)\n",
    "\n",
    "loc = []\n",
    "for i in locn_:\n",
    "    loc.append(i.text)\n",
    "\n",
    "Company = []\n",
    "for i in company:\n",
    "    Company.append(i.text)\n",
    "    \n",
    "# Dataframe of all the tabs\n",
    "Jobs=pd.DataFrame()\n",
    "Jobs['Job Title']=job_\n",
    "Jobs['Job Location']=loc\n",
    "Jobs['Company Name']=Company\n",
    "Jobs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7acd932",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown in the given image - You have to use the location and salary filter,You have to scrape data for “Data Scientist” designation for first 10 job results,You have to scrape the job-title, job-location, company name, experience required,The location filter to be used is “Delhi/NCR”,The salary filter to be used is “3-6” lakhs.\n",
    "\n",
    "Answer :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75ebf0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6984ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Web Element For Search Job Bar -\n",
    "job1 = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "# Write on search bar\n",
    "job1.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4de3901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Search Using Absolute Xpath Function -\n",
    "search1 = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "# Search Button Will Get Clicked\n",
    "search1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e765b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location filter to be used is “Delhi/NCR”.\n",
    "Location_check = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/p/span[1]\")\n",
    "Location_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62f16c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The salary filter to be used is “3-6” lakhs.\n",
    "Salary_check = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/p/span[1]\")\n",
    "Salary_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "346a8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract All The Data Needed From The Site - Scrape The Job-Title, Job-Location, Company_Name, Experience_Required -\n",
    "\n",
    "# Job Titles -\n",
    "title1 = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "# Job Location -\n",
    "locn1 = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "# Company -\n",
    "company1 = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "# Experience - \n",
    "exp1 = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c493d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Senior DS/ Team Lead</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram(Cyber City +1)</td>\n",
       "      <td>NebulARC Technologies Private Limited</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist | Python | Machine Learning | D...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Schlesinger Group</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job Opportunity || Data Scientist || HCL Techn...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>HCL</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For Data Analyst / Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>Careerera</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram(Uday Nagar)</td>\n",
       "      <td>Core Diagnostics Private Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Openings For Jr/mid/Sr level data Scientists</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Pluto seven business solutions (p) limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>T &amp; A Solutions</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0              Data Scientist / Senior DS/ Team Lead   \n",
       "1  Data Scientist | Python | Machine Learning | D...   \n",
       "2  Job Opportunity || Data Scientist || HCL Techn...   \n",
       "3           Hiring For Data Analyst / Data Scientist   \n",
       "4                            Senior Data Scientist I   \n",
       "5                                     Data Scientist   \n",
       "6       Openings For Jr/mid/Sr level data Scientists   \n",
       "7                                     Data Scientist   \n",
       "8                   Urgent Hiring For Data Scientist   \n",
       "9                   Urgent Hiring For Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0            Mumbai, Gurgaon/Gurugram(Cyber City +1)   \n",
       "1               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "2                                        Delhi / NCR   \n",
       "3                             Noida(Sector-59 Noida)   \n",
       "4                                   Gurgaon/Gurugram   \n",
       "5                       Gurgaon/Gurugram(Uday Nagar)   \n",
       "6  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "9              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                                 Company Name Job Experience  \n",
       "0       NebulARC Technologies Private Limited        0-4 Yrs  \n",
       "1                           Schlesinger Group        0-3 Yrs  \n",
       "2                                         HCL        2-6 Yrs  \n",
       "3                                   Careerera        2-5 Yrs  \n",
       "4                                   Delhivery        3-7 Yrs  \n",
       "5            Core Diagnostics Private Limited        2-7 Yrs  \n",
       "6  Pluto seven business solutions (p) limited        2-6 Yrs  \n",
       "7                             T & A Solutions        2-6 Yrs  \n",
       "8     Mount Talent Consulting Private Limited        1-6 Yrs  \n",
       "9     Mount Talent Consulting Private Limited        1-6 Yrs  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Text From Elements -\n",
    "job_title1 = []\n",
    "for i in title1:\n",
    "    job_title1.append(i.text)\n",
    "\n",
    "location1 = []\n",
    "for i in locn1:\n",
    "    location1.append(i.text)\n",
    "\n",
    "Company_name1 = []\n",
    "for i in company1:\n",
    "    Company_name1.append(i.text)\n",
    "\n",
    "Experience1 = []\n",
    "for i in exp1:\n",
    "    Experience1.append(i.text)\n",
    "    \n",
    "# Dataframe of all the tabs\n",
    "Naukari=pd.DataFrame()\n",
    "Naukari['Job Title']=job_title1\n",
    "Naukari['Job Location']=location1\n",
    "Naukari['Company Name']=Company_name1\n",
    "Naukari['Job Experience']=Experience1\n",
    "Naukari[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf48bd",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: Brand, Product Description, Price.\n",
    "\n",
    "Answer :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae47c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50fab289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get the popup so I added it to close it -\n",
    "Close = driver.find_element_by_xpath('/html/body/div[2]/div/div/button')\n",
    "Close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1d6da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “sunglasses” in the search field where “search for products, brands andmore” is written and click the search icon\n",
    "\n",
    "# Finding Web Element For Search Product Bar -\n",
    "Product = driver.find_element_by_class_name(\"_3704LK\")\n",
    "# Write on search bar\n",
    "Product.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22ec1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Search -\n",
    "search2 = driver.find_element_by_class_name(\"L0Z3Pu\")\n",
    "# Search Button Will Get Clicked\n",
    "search2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bf610e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Data From The Site Page 1 - Scrape Brand, Product Description, Price - 40 sunglasses\n",
    "\n",
    "# Brand -\n",
    "brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "# Product Description -\n",
    "description = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "# Price -\n",
    "price = driver.find_elements_by_xpath('//a[@class=\"_3bPFwb\"]')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "B = []\n",
    "for i in brand:\n",
    "    B.append(i.text)\n",
    "D = []\n",
    "for i in description:\n",
    "    D.append(i.text)\n",
    "P = []\n",
    "for i in price:\n",
    "    P.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ee9674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Next Button Using Absolute Xpath Function -\n",
    "Next = driver.find_element_by_class_name(\"_1LKTO3\")\n",
    "# Next Button Will Get Clicked\n",
    "Next.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be564292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Data From The Site Page 2 - Scrape Brand, Product Description, Price - 40 sunglasses\n",
    "\n",
    "# Brand -\n",
    "brand1 = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "# Product Description -\n",
    "description1 = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "# Price -\n",
    "price1 = driver.find_elements_by_xpath('//a[@class=\"_3bPFwb\"]')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "B1 = []\n",
    "for i in brand1:\n",
    "    B1.append(i.text)\n",
    "D1 = []\n",
    "for i in description1:\n",
    "    D1.append(i.text)\n",
    "P1 = []\n",
    "for i in price1:\n",
    "    P1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6183b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Next Button Using Absolute Xpath Function -\n",
    "Next = driver.find_element_by_class_name(\"_1LKTO3\")\n",
    "# Next Button Will Get Clicked\n",
    "Next.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "709ce314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Data From The Site Page 2 - Scrape Brand, Product Description, Price - 20 sunglasses\n",
    "\n",
    "# Brand -\n",
    "brand2 = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "# Product Description -\n",
    "description2 = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "# Price -\n",
    "price2 = driver.find_elements_by_xpath('//a[@class=\"_3bPFwb\"]')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "B2 = []\n",
    "for i in brand2:\n",
    "    B2.append(i.text)\n",
    "D2 = []\n",
    "for i in description2:\n",
    "    D2.append(i.text)\n",
    "P2 = []\n",
    "for i in price2:\n",
    "    P2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e0f147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged All The Lists For Creating DataFrame\n",
    "FB=B+B1+B2\n",
    "FD=D+D1+D2\n",
    "FP=P+P1+P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79591a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Round Sun...</td>\n",
       "      <td>₹1,179₹1,99941% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹599₹2,99980% off\\nFree delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹200₹1,59987% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248₹2,49590% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹198₹1,29984% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹999₹1,99950% off\\nFree delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (32)</td>\n",
       "      <td>₹383₹1,99980% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹190₹1,59988% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Riding Glasses, Others Aviator,...</td>\n",
       "      <td>₹181₹99981% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹203₹69970% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product Description  \\\n",
       "0       VINCENT CHASE  by Lenskart Polarized, UV Protection Round Sun...   \n",
       "1        Singco India  Gradient, Toughened Glass Lens, UV Protection ...   \n",
       "2              PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "3           Elligator                UV Protection Round Sunglasses (54)   \n",
       "4                SRPM             UV Protection Wayfarer Sunglasses (56)   \n",
       "..                ...                                                ...   \n",
       "95      VINCENT CHASE  UV Protection, Gradient Rectangular Sunglasses...   \n",
       "96     ROZZETTA CRAFT             UV Protection Wayfarer Sunglasses (32)   \n",
       "97             PIRASO  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "98  SHAAH COLLECTIONS  UV Protection, Riding Glasses, Others Aviator,...   \n",
       "99       Singco India   Mirrored, UV Protection Wayfarer Sunglasses (53)   \n",
       "\n",
       "                               Price  \n",
       "0                ₹1,179₹1,99941% off  \n",
       "1   ₹599₹2,99980% off\\nFree delivery  \n",
       "2                  ₹200₹1,59987% off  \n",
       "3                  ₹248₹2,49590% off  \n",
       "4                  ₹198₹1,29984% off  \n",
       "..                               ...  \n",
       "95  ₹999₹1,99950% off\\nFree delivery  \n",
       "96                 ₹383₹1,99980% off  \n",
       "97                 ₹190₹1,59988% off  \n",
       "98                   ₹181₹99981% off  \n",
       "99                   ₹203₹69970% off  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe of all the tabs\n",
    "sunglasses=pd.DataFrame()\n",
    "sunglasses['Brand']=FB[:100]\n",
    "sunglasses['Product Description']=FD[:100]\n",
    "sunglasses['Price']=FP[:100]\n",
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2867b70",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https:// www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace. scrape the attributes 1.Rating 2.Review summary 3.Full review scrape this data for first 100 reviews.\n",
    "\n",
    "Answer :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d9d5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c6381b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking All Reviews Using Absolute Xpath Function -\n",
    "All = driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div/div/div[5]/div/a/div\")\n",
    "# Button Will Get Clicked\n",
    "All.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c33ff01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_Summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5     Perfect product!   \n",
       "3       5  Best in the market!   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5            Fabulous!   \n",
       "96      5        Great product   \n",
       "97      4          Good choice   \n",
       "98      5   Highly recommended   \n",
       "99      5    Worth every penny   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Great iPhone very snappy experience as apple k...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first iOS phone. I am very happy wi...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  So far it’s been an AMAZING experience coming ...  \n",
       "98  What a camera .....just awesome ..you can feel...  \n",
       "99  i11 is worthy to buy, too much happy with the ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_list = []\n",
    "  \n",
    "for page in range(1, 11, 1):\n",
    "    \n",
    "    page_url = \"/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page=1\"+ str(page)\n",
    "    rating = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    review_summary = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    full_review = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    for i in range(len(rating)):\n",
    "        element_list.append([rating[i].text, review_summary[i].text, full_review[i].text])\n",
    "\n",
    "R=100\n",
    "r = [i[0] for i in element_list[ : R]]\n",
    "\n",
    "RS=100\n",
    "rs = [i[1] for i in element_list[ : RS]]\n",
    "\n",
    "FR=100\n",
    "fr = [i[2] for i in element_list[ : FR]]\n",
    "\n",
    "iphone=pd.DataFrame()\n",
    "iphone['Rating']=r\n",
    "iphone['Review_Summary']=rs\n",
    "iphone['Full_Review']=fr\n",
    "iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44ef827",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the search field.\n",
    "\n",
    "Answer:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5faff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.flipkart.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1190b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search \"sneakers\"\n",
    "# Finding Web Element For Search Product Bar -\n",
    "sneakers = driver.find_element_by_class_name(\"_3704LK\")\n",
    "# Write on search bar\n",
    "sneakers.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40387f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Search Using Absolute Xpath Function -\n",
    "search = driver.find_element_by_class_name(\"L0Z3Pu\")\n",
    "# Search Button Will Get Clicked\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b52932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Data From The Site Page 1 - Scrape Brand, Product Description, Price - 40 sneakers\n",
    "# Brand -\n",
    "brand = driver.find_elements_by_class_name('_2WkVRV')\n",
    "\n",
    "# Product Description -\n",
    "description = driver.find_elements_by_class_name('IRpwTa')\n",
    "\n",
    "# Price -\n",
    "price = driver.find_elements_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[1]')\n",
    "\n",
    "# Discount -\n",
    "dis = driver.find_elements_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[3]/span')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "B = []\n",
    "for i in brand:\n",
    "    B.append(i.text)\n",
    "D = []\n",
    "for i in description:\n",
    "    D.append(i.text)\n",
    "P = []\n",
    "for i in price:\n",
    "    P.append(i.text)\n",
    "S = []\n",
    "for i in dis:\n",
    "    S.append(i.text)\n",
    "S.insert(-6, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "286b2c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Next Button Using Absolute Xpath Function -\n",
    "Next_ = driver.find_element_by_xpath(\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span\")\n",
    "# Next Button Will Get Clicked\n",
    "Next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6586b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Data From The Site Page 2 - Scrape Brand, Product Description, Price - 40 sneakers\n",
    "# Brand -\n",
    "brand_1 = driver.find_elements_by_class_name('_2WkVRV')\n",
    "\n",
    "# Product Description -\n",
    "description_1 = driver.find_elements_by_class_name('IRpwTa')\n",
    "\n",
    "# Price -\n",
    "price_1 = driver.find_elements_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[1]')\n",
    "\n",
    "# Discount -\n",
    "dis1 = driver.find_elements_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[3]/span')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "B_1 = []\n",
    "for i in brand_1:\n",
    "    B_1.append(i.text)\n",
    "D_1 = []\n",
    "for i in description_1:\n",
    "    D_1.append(i.text)\n",
    "P_1 = []\n",
    "for i in price_1:\n",
    "    P_1.append(i.text)\n",
    "S1 = []\n",
    "for i in dis1:\n",
    "    S1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfc36543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Next Button Using Absolute Xpath Function -\n",
    "Next_ = driver.find_element_by_xpath(\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span\")\n",
    "# Next Button Will Get Clicked\n",
    "Next_.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65f8d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Data From The Site Page 2 - Scrape Brand, Product Description, Price - 20 sneakers\n",
    "# Brand -\n",
    "brand_2 = driver.find_elements_by_class_name('_2WkVRV')\n",
    "\n",
    "# Product Description -\n",
    "description_2 = driver.find_elements_by_class_name('IRpwTa')\n",
    "\n",
    "# Price -\n",
    "price_2 = driver.find_elements_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[1]')\n",
    "\n",
    "# Discount - \n",
    "dis2 = driver.find_elements_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div/div/div/div/div/a[2]/div/div[3]/span')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "B_2 = []\n",
    "for i in brand_2:\n",
    "    B_2.append(i.text)\n",
    "D_2 = []\n",
    "for i in description_2:\n",
    "    D_2.append(i.text)\n",
    "P_2 = []\n",
    "for i in price_2:\n",
    "    P_2.append(i.text)\n",
    "S2 = []\n",
    "for i in dis2:\n",
    "    S2.append(i.text)\n",
    "S2.insert(18, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfa722b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged All The Lists For Creating DataFrame\n",
    "FBS=B+B_1+B_2\n",
    "FDS=D+D_1+D_2\n",
    "FPS=P+P_1+P_2\n",
    "FSS=S+S1+S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc6d014a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Echor Men's Sneakers Fashion Lightweight Runni...</td>\n",
       "      <td>₹569</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic leather Sneakers For Men</td>\n",
       "      <td>Free delivery</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹166</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Men's Canvas Low Top Sneakers Lace-up Classic ...</td>\n",
       "      <td>₹1,648</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>D-SNEAKERZ</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>Free delivery</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Starlinc</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹190</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Classic Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description  \\\n",
       "0            Echor  Echor Men's Sneakers Fashion Lightweight Runni...   \n",
       "1             aadi                 Synthetic leather Sneakers For Men   \n",
       "2   luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...   \n",
       "3         Magnolia                                   Sneakers For Men   \n",
       "4           Labbin                                   Sneakers For Men   \n",
       "..             ...                                                ...   \n",
       "95        RED TAPE                                   Sneakers For Men   \n",
       "96           Echor  Men's Canvas Low Top Sneakers Lace-up Classic ...   \n",
       "97      D-SNEAKERZ  Casual , Partywear Sneakers Shoes For Men's An...   \n",
       "98        Starlinc                                   Sneakers For Men   \n",
       "99        RED TAPE                           Classic Sneakers For Men   \n",
       "\n",
       "            Price Discount  \n",
       "0            ₹569  62% off  \n",
       "1   Free delivery  50% off  \n",
       "2            ₹499  65% off  \n",
       "3            ₹449  60% off  \n",
       "4            ₹398  50% off  \n",
       "..            ...      ...  \n",
       "95           ₹166  70% off  \n",
       "96         ₹1,648  74% off  \n",
       "97  Free delivery  61% off  \n",
       "98           ₹190  76% off  \n",
       "99           ₹499           \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe of all the tabs\n",
    "sneakers=pd.DataFrame()\n",
    "sneakers['Brand']=FBS[:100]\n",
    "sneakers['Product Description']=FDS[:100]\n",
    "sneakers['Price']=FPS[:100]\n",
    "sneakers['Discount']=FSS[:100]\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d85d1",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image. And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe.\n",
    "\n",
    "Answer :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44197028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "956e3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "Price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7330d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Color = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label')\n",
    "Color.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40b8498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Data From The Site Page 1 - Scrape Brand, Shoe Description, Price - 50 sneakers\n",
    "# Brand -\n",
    "shoe = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "\n",
    "# Shoe Description -\n",
    "desc = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "\n",
    "# Price -\n",
    "pri = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "S = []\n",
    "for i in shoe:\n",
    "    S.append(i.text)\n",
    "C = []\n",
    "for i in desc:\n",
    "    C.append(i.text)\n",
    "R = []\n",
    "for i in pri:\n",
    "    R.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f12ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Next Button Using Absolute Xpath Function -\n",
    "Next_B = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a\")\n",
    "# Next Button Will Get Clicked\n",
    "Next_B.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b76b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Data From The Site Page 2 - Scrape Brand, Shoe Description, Price - 50 sneakers\n",
    "# Brand -\n",
    "shoe1 = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "\n",
    "# Shoe Description -\n",
    "desc1 = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "\n",
    "# Price -\n",
    "pri1 = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "S1 = []\n",
    "for i in shoe1:\n",
    "    S1.append(i.text)\n",
    "C1 = []\n",
    "for i in desc1:\n",
    "    C1.append(i.text)\n",
    "R1 = []\n",
    "for i in pri1:\n",
    "    R1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7be652e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men FREE 5.0 NEXT NATURE Run</td>\n",
       "      <td>Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 7149Rs. 12999(45% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Magnify Nitro Running</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 7999Rs. 9999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Men Mid-Top Chelsea Boots</td>\n",
       "      <td>Rs. 9265Rs. 10900(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Solid Leather Formal Loafers</td>\n",
       "      <td>Rs. 8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ECCO</td>\n",
       "      <td>Leather Stiletto Pumps</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 7999Rs. 9999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ECCO</td>\n",
       "      <td>Women Textured Leather Sneakers</td>\n",
       "      <td>Rs. 13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Above The Knee Boots</td>\n",
       "      <td>Rs. 14025Rs. 16500(15% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                       Description  \\\n",
       "0             Nike      Men FREE 5.0 NEXT NATURE Run   \n",
       "1             Puma                 Men Running Shoes   \n",
       "2             Puma         Men Magnify Nitro Running   \n",
       "3          Bugatti                 Men Running Shoes   \n",
       "4          Saint G         Men Mid-Top Chelsea Boots   \n",
       "..             ...                               ...   \n",
       "95        DAVINCHI  Men Solid Leather Formal Loafers   \n",
       "96            ECCO            Leather Stiletto Pumps   \n",
       "97  ROSSO BRUNELLO   Men Solid Leather Formal Derbys   \n",
       "98            ECCO   Women Textured Leather Sneakers   \n",
       "99         Saint G      Leather Above The Knee Boots   \n",
       "\n",
       "                          Price  \n",
       "0                      Rs. 8295  \n",
       "1    Rs. 7149Rs. 12999(45% OFF)  \n",
       "2    Rs. 7799Rs. 12999(40% OFF)  \n",
       "3     Rs. 7999Rs. 9999(20% OFF)  \n",
       "4    Rs. 9265Rs. 10900(15% OFF)  \n",
       "..                          ...  \n",
       "95                     Rs. 8490  \n",
       "96                    Rs. 12999  \n",
       "97    Rs. 7999Rs. 9999(20% OFF)  \n",
       "98                    Rs. 13999  \n",
       "99  Rs. 14025Rs. 16500(15% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shoe=pd.DataFrame({'Brand':S,'Description':C,'Price':R})\n",
    "Shoe1=pd.DataFrame({'Brand':S1,'Description':C1,'Price':R1})\n",
    "pd.concat([Shoe,Shoe1])\n",
    "index = pd.Index(range(0, 100, 1))\n",
    "dfShoe = pd.concat([Shoe,Shoe1]).set_index(index)\n",
    "dfShoe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42601e2d",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”. After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:Title,Ratings,Price.\n",
    "\n",
    "Answer :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc7e71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c06b0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Element For Search \"Laptop\" -\n",
    "Lap = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "# Write on search bar\n",
    "Lap.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "390811bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Search Using Absolute Xpath Function -\n",
    "search_Lap = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "# Search Button Will Get Clicked\n",
    "search_Lap.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "658b03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set CPU Type filter to “Intel Core i7” and “Intel Core i9” -\n",
    "CPUi7 = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/div/div/div[1]/div/span[1]/a[11]/div')\n",
    "CPUi7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e152c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook - XMA1904-AF</td>\n",
       "      <td></td>\n",
       "      <td>₹57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>₹65,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td></td>\n",
       "      <td>₹59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td></td>\n",
       "      <td>₹82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 13, 11th Gen Intel Core i7, 13.3-i...</td>\n",
       "      <td></td>\n",
       "      <td>₹59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...</td>\n",
       "      <td></td>\n",
       "      <td>₹82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acer Predator Helios 300 Gaming Laptop 11th Ge...</td>\n",
       "      <td></td>\n",
       "      <td>₹89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell Latitude E6430 14.1 Inch Busine...</td>\n",
       "      <td></td>\n",
       "      <td>₹1,35,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 14, Intel 11th Gen Core i7 16GB RA...</td>\n",
       "      <td></td>\n",
       "      <td>₹87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...</td>\n",
       "      <td></td>\n",
       "      <td>₹1,48,650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings      Price\n",
       "0                           Mi Notebook - XMA1904-AF            ₹57,990\n",
       "1  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...            ₹65,999\n",
       "2  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...            ₹59,990\n",
       "3  Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...            ₹82,990\n",
       "4  HP Pavilion 13, 11th Gen Intel Core i7, 13.3-i...            ₹59,990\n",
       "5  Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...            ₹82,990\n",
       "6  Acer Predator Helios 300 Gaming Laptop 11th Ge...            ₹89,990\n",
       "7  (Renewed) Dell Latitude E6430 14.1 Inch Busine...          ₹1,35,999\n",
       "8  HP Pavilion 14, Intel 11th Gen Core i7 16GB RA...            ₹87,990\n",
       "9  Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...          ₹1,48,650"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape first 10 laptops data Title,Ratings,Price -\n",
    "\n",
    "# Title -\n",
    "Title = driver.find_elements_by_tag_name('h2')\n",
    "\n",
    "# Ratings -\n",
    "Ratings = driver.find_elements_by_tag_name('i')\n",
    "\n",
    "# Price -\n",
    "Price = driver.find_elements_by_class_name('a-price')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "T = []\n",
    "for i in Title:\n",
    "    T.append(i.text)\n",
    "\n",
    "R = []\n",
    "for i in Ratings:\n",
    "    R.append(i.text)\n",
    "\n",
    "P = []\n",
    "for i in Price:\n",
    "    P.append(i.text)\n",
    "\n",
    "Laptop=pd.DataFrame({})\n",
    "Laptop['Title']=T[:10]\n",
    "Laptop['Ratings']=R[:10]\n",
    "Laptop['Price']=P[:10]\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113f381",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "\n",
    "Answer:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67b179a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a046876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Job Button Using Absolute Xpath Function -\n",
    "Job = driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[6]\")\n",
    "# Job Button Will Get Clicked\n",
    "Job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a19b483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Web Element For Search Job Bar -\n",
    "data = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input\")\n",
    "# Write on search bar\n",
    "data.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b87ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Search Button Using Absolute Xpath Function -\n",
    "Check = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/button')\n",
    "# Search Button Will Get Clicked\n",
    "Check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "939a5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on location and in place of “Search location”\n",
    "Loc = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]\")\n",
    "Loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10676ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Noida” and select location “Noida” -\n",
    "Loc1 = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "Loc1.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d31c974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "N.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "59ce9248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>No.of Days ago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HCL</td>\n",
       "      <td>22hr ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ameriprise Financial</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>22d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>22d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>22d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cargoflash Infotech</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Company No.of Days ago Rating\n",
       "0                         HCL       22hr ago    3.8\n",
       "1  Jubilant Foodworks Limited         1d ago    3.9\n",
       "2        Ameriprise Financial         3d ago    4.0\n",
       "3                       Paytm         9d ago    3.7\n",
       "4                CHT Sapiense        10d ago    3.8\n",
       "5                CHT Sapiense        11d ago    3.8\n",
       "6                    GI Group        22d ago    4.1\n",
       "7                    GI Group        22d ago    4.1\n",
       "8                    GI Group        22d ago    4.1\n",
       "9         Cargoflash Infotech         2d ago    3.8"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then scrape the data for the first 10 jobs results you get on the above shown page -\n",
    "# Scrape company name, No. of days ago when job was posted, Rating of the company -\n",
    "\n",
    "# Company Name -\n",
    "company = driver.find_elements_by_xpath('//p[@class=\"company body-medium\"]')\n",
    "\n",
    "# No. of days ago when job was posted -\n",
    "days = driver.find_elements_by_xpath('//span[@class=\"body-small-l\"]')\n",
    "\n",
    "# Rating of the company -\n",
    "rate = driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "c = []\n",
    "for i in company:\n",
    "    c.append(i.text)\n",
    "n = []\n",
    "for i in days:\n",
    "    n.append(i.text)\n",
    "del n[::-2]\n",
    "    \n",
    "r = []\n",
    "for i in rate:\n",
    "    r.append(i.text)\n",
    "    \n",
    "Ambition=pd.DataFrame({'Company':c,'No.of Days ago':n,'Rating':r})\n",
    "Ambition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb01ab4",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation. \n",
    "\n",
    "Answer:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "470e63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The Webpage\n",
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c26cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the salaries option -\n",
    "salary = driver.find_element_by_xpath('/html/body/div[1]/nav/nav')\n",
    "# Job Button Will Get Clicked\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27fbd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist” -\n",
    "place = driver.find_element_by_xpath('//*[@id=\"jobProfileSearchbox\"]')\n",
    "place.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d611812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "place = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]')\n",
    "place.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22b9b86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Total_Salary_Record</th>\n",
       "      <th>Average_Salary</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 28.7L</td>\n",
       "      <td>₹ 17.7L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>Data Scientist . 3 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>Data Scientist . 3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>Data Scientist . 2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 72 salaries</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>Data Scientist . 2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 23 salaries</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "      <td>Data Scientist . 3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>Data Scientist . 2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "      <td>Data Scientist . 3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>Data Scientist . 4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>Data Scientist . 4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 42 salaries</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "      <td>Data Scientist . 3-4 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company   Total_Salary_Record Average_Salary Min_Salary  \\\n",
       "0                   Walmart  based on 10 salaries        ₹ 28.7L    ₹ 17.7L   \n",
       "1                  Ab Inbev  based on 22 salaries        ₹ 19.5L    ₹ 15.0L   \n",
       "2                        ZS  based on 14 salaries        ₹ 15.8L     ₹ 9.8L   \n",
       "3         Fractal Analytics  based on 72 salaries        ₹ 15.0L     ₹ 9.5L   \n",
       "4                     Optum  based on 23 salaries        ₹ 15.0L    ₹ 11.0L   \n",
       "5              UnitedHealth  based on 49 salaries        ₹ 13.5L     ₹ 7.2L   \n",
       "6           Tiger Analytics  based on 27 salaries        ₹ 13.5L     ₹ 8.3L   \n",
       "7                   Verizon  based on 14 salaries        ₹ 12.7L    ₹ 10.0L   \n",
       "8  Ganit Business Solutions  based on 13 salaries        ₹ 12.4L     ₹ 8.5L   \n",
       "9                  Ericsson  based on 42 salaries        ₹ 11.9L     ₹ 5.8L   \n",
       "\n",
       "  Max_Salary           Experience_Required  \n",
       "0    ₹ 35.0L    Data Scientist . 3 yrs exp  \n",
       "1    ₹ 25.0L  Data Scientist . 3-4 yrs exp  \n",
       "2    ₹ 20.0L    Data Scientist . 2 yrs exp  \n",
       "3    ₹ 22.0L  Data Scientist . 2-4 yrs exp  \n",
       "4    ₹ 21.3L  Data Scientist . 3-4 yrs exp  \n",
       "5    ₹ 20.5L  Data Scientist . 2-4 yrs exp  \n",
       "6    ₹ 18.5L  Data Scientist . 3-4 yrs exp  \n",
       "7    ₹ 21.0L    Data Scientist . 4 yrs exp  \n",
       "8    ₹ 15.0L    Data Scientist . 4 yrs exp  \n",
       "9    ₹ 21.5L  Data Scientist . 3-4 yrs exp  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required -\n",
    "\n",
    "# Company Name -\n",
    "company = driver.find_elements_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div/div/div/div/div/a')\n",
    "\n",
    "# Total salary record \n",
    "Total_salary = driver.find_elements_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div/div[1]/div/div/div[1]/span')\n",
    "\n",
    "# Average salary -\n",
    "Avg_salary = driver.find_elements_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div/div[2]/div/div/div/p')\n",
    "\n",
    "# Minimum salary -\n",
    "Min_salary = driver.find_elements_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div/div[2]/div/div[2]/div[1]')\n",
    "\n",
    "# Maximum salary -\n",
    "Max_salary = driver.find_elements_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div/div[2]/div/div/div[2]')\n",
    "\n",
    "# experience required -\n",
    "exp = driver.find_elements_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div/div[1]/div/div/div[2]')\n",
    "\n",
    "# Extract Text From Elements -\n",
    "cn = []\n",
    "for i in company:\n",
    "    cn.append(i.text)\n",
    "ts = []\n",
    "for i in Total_salary:\n",
    "    ts.append(i.text)\n",
    "rs = []\n",
    "for i in Avg_salary:\n",
    "    rs.append(i.text)\n",
    "ms = []\n",
    "for i in Min_salary:\n",
    "    ms.append(i.text)\n",
    "xs = []\n",
    "for i in Max_salary:\n",
    "    xs.append(i.text)\n",
    "ex = []\n",
    "for i in exp:\n",
    "    ex.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "Ambitionbox=pd.DataFrame({'Company':cn,'Total_Salary_Record':ts,'Average_Salary':rs,'Min_Salary':ms,'Max_Salary':xs,'Experience_Required':ex})\n",
    "Ambitionbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76097dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
